{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsun75/dataAnalysis/blob/main/2_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D_04_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91_%EB%8F%99%EC%A0%81%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%A7%81_%EB%B0%B0%ED%8F%AC_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fJ5O84wPYPL",
      "metadata": {
        "id": "4fJ5O84wPYPL"
      },
      "source": [
        "# 데이터 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5EeG6TDjPY8n",
      "metadata": {
        "id": "5EeG6TDjPY8n"
      },
      "source": [
        "## 4. 웹 크롤링으로 데이터 수집 - 동적 웹크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hu6wdFx6QFkN",
      "metadata": {
        "id": "Hu6wdFx6QFkN"
      },
      "source": [
        "### 1) 웹 크롤링 기초"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lS04IwMiQGxb",
      "metadata": {
        "id": "lS04IwMiQGxb"
      },
      "source": [
        "### 2) 정적 크롤링(스크래핑)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlUTfO8OPZE1",
      "metadata": {
        "id": "GlUTfO8OPZE1"
      },
      "source": [
        "### 3) 동적 크롤링(Visual Studio Code 사용)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfff7426",
      "metadata": {
        "id": "dfff7426"
      },
      "source": [
        "- 공식페이지: https://www.selenium.dev/\n",
        "- 참고: https://wikidocs.net/198942"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c531bf",
      "metadata": {
        "id": "76c531bf"
      },
      "source": [
        "- https://chromedriver.chromium.org/\n",
        "- 최신 chrome webdriver 다운로드\n",
        "- 코드가 있는 위치에 chromedriver.exe파일 옮겨놓는다.\n",
        "- 자신의 크롬 웹 브라우저의 버전을 확인하고 버전에 맞는 것을 다운로드해야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baf83cdb",
      "metadata": {
        "id": "baf83cdb"
      },
      "source": [
        "#### 자신의 PC 폰트 목록 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de9e8da",
      "metadata": {
        "id": "9de9e8da"
      },
      "outputs": [],
      "source": [
        "#(windows) 폰트 목록 가져오기\n",
        "import matplotlib.font_manager as fm\n",
        "font_list_win = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "print(f'windows 폰트 목록 : {font_list_win}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5b64c6",
      "metadata": {
        "id": "5a5b64c6"
      },
      "outputs": [],
      "source": [
        "#(Mac) 폰트 목록 가져오기\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "font_list_mac = fm.OSXInstalledFonts()\n",
        "print(f'Mac 폰트 목록 : {font_list_mac}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e1b434",
      "metadata": {
        "id": "61e1b434"
      },
      "source": [
        "- **한글 폰트 지정하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf54b67d",
      "metadata": {
        "id": "cf54b67d"
      },
      "outputs": [],
      "source": [
        "# 코랩에서 한글 폰트 종류와 이름이 win과 다를 수 있다!!!\n",
        "# 코랩: NanumGothic, 윈도우: Malgun Gothic\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.family': 'Malgun Gothic',\n",
        "                     'font.size': 12,\n",
        "                     'figure.figsize': (6, 4),\n",
        "                     'axes.unicode_minus':  False }) # 폰트 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73553a7",
      "metadata": {
        "id": "c73553a7"
      },
      "source": [
        "#### 1.라이브러리 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89d7109",
      "metadata": {
        "id": "b89d7109"
      },
      "outputs": [],
      "source": [
        "# 동적 크롤링을 위한 라이브러리\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a629dc77",
      "metadata": {
        "id": "a629dc77",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install chromedriver-autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281f2c4e",
      "metadata": {
        "id": "281f2c4e"
      },
      "outputs": [],
      "source": [
        "import selenium\n",
        "selenium.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd87b66",
      "metadata": {
        "id": "ebd87b66"
      },
      "source": [
        "#### 2.ChromeDriver 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf60499d",
      "metadata": {
        "id": "bf60499d"
      },
      "source": [
        "* ChromeDriver 사용방법\n",
        "    - 방법1 : **chromedriver-autoinstaller 라이브러리 사용해서 버전 고려 안하기(쉬움)**\n",
        "    - 방법2 : 버전 업데이트마다 PC에 ChromeDriver.exe 드라이버 재설치(복잡함)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17142302",
      "metadata": {
        "id": "17142302"
      },
      "source": [
        "* ChromeDriver 동작 확인\n",
        "    - 크롬 브라우저에 'Chrome이 자동화된 테스트 소프트웨어에 의해 제어되고 있습니다' 문구와 함께 화면이 뜨면 성공!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa86b594",
      "metadata": {
        "id": "fa86b594"
      },
      "outputs": [],
      "source": [
        "import chromedriver_autoinstaller # chrome driver 자동 설치 라이브러리\n",
        "from selenium import webdriver\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "options = webdriver.ChromeOptions() # Browser 세팅하기\n",
        "options.add_argument('lang=ko_KR') # 사용언어 한국어\n",
        "options.add_argument('disable-gpu') # 하드웨어 가속 안함\n",
        "# options.add_argument('headless') # 창 숨기기\n",
        "\n",
        "# # 브라우저 세팅\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# 브라우저에 URL 호출하기\n",
        "driver.get(url='https://www.naver.com/')\n",
        "\n",
        "# 브라우저 탭 닫기\n",
        "driver.close()\n",
        "\n",
        "# 브라우저 종료하기 (탭 모두 종료)\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc52e0c5",
      "metadata": {
        "id": "bc52e0c5"
      },
      "source": [
        "- 간단하게 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0e5a15a",
      "metadata": {
        "id": "c0e5a15a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# 웹페이지로 이동\n",
        "driver.get('https://www.naver.com/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac30b7d",
      "metadata": {
        "id": "bac30b7d"
      },
      "source": [
        "---------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ff3753",
      "metadata": {
        "id": "87ff3753"
      },
      "source": [
        "#### 3. Selenium을 사용하여 동적 웹 페이지와 상호작용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6170ea5e",
      "metadata": {
        "id": "6170ea5e"
      },
      "source": [
        "* **(클릭 이벤트를 위한 xpath 복사)작업 순서**\n",
        "    - 크롬에서 target 페이지 접속(https://www.naver.com/)\n",
        "    - F12 눌러 오른쪽 영역에 개발자 페이지 나타나도록 함(html코드 나타남)\n",
        "    - ctrl+shift+c 누른 상태에서 클릭 이벤트 발생할 곳 찾아 마우스 클릭\n",
        "    - 해당 html코드 영역에서 마우스 오른쪽키 누르고 copy>copy.xpath 메뉴 선택하여 이벤트 코드 클립보드에 복사\n",
        "    - driver.find_element(By.XPATH, '복사되니 부분 붙여넣기').click()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1a352f",
      "metadata": {
        "id": "6b1a352f"
      },
      "source": [
        "* **[사용방법] 버튼(링크) 클릭**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7005f89",
      "metadata": {
        "id": "f7005f89",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# 웹페이지로 이동\n",
        "driver.get('https://www.naver.com/')\n",
        "\n",
        "# 클릭(copy.xpath 이용)\n",
        "search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]')\n",
        "search_button.click()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56040955",
      "metadata": {
        "id": "56040955"
      },
      "source": [
        "#### [1단계] 네이버 메인페이지에서 검색어 입력하고 버튼 클릭하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c43c66f",
      "metadata": {
        "id": "8c43c66f"
      },
      "outputs": [],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "def naver_main_search(driver, keyword):\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# 1.네이버 메인 검색\n",
        "keyword = '눈물의여왕'\n",
        "naver_main_search(driver, keyword)\n",
        "print(f'현재URL : {driver.current_url}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3462821",
      "metadata": {
        "id": "f3462821"
      },
      "source": [
        "#### [2단계] 네이버 검색 결과 페이지에서 다시 버튼 클릭\n",
        "- 버튼 클릭 위치 확인(xPath) : 마우스오른쪽버튼 > Copy >Copy xPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0f56d8",
      "metadata": {
        "id": "3b0f56d8"
      },
      "outputs": [],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword) # 검색창에 검색어 반영\n",
        "    search_button.click() # 클릭 이벤트\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 다른 탭 선택 ( 마우스오른쪽버튼 > Copy >Copy xPath)\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a' )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d15d93",
      "metadata": {
        "id": "f0d15d93"
      },
      "source": [
        "#### [3단계] 네이버 검색 다른 탭 정보 추출하기 : 제목, 상세설명, 링크\n",
        "- 추출할 정보의 정확한 위치 확인 후 --> 적절히 코드 수정후 실행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978ecf6f",
      "metadata": {
        "id": "978ecf6f"
      },
      "outputs": [],
      "source": [
        "import chromedriver_autoinstaller\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# chrome driver를 자동으로 설치함\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭(첫번째 탭) 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 다른 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 3] : 다른 탭 페이지에서 정보(ex: 제목,상세,링크) 추출\n",
        "def naver_html_parse(html):\n",
        "    print('\\n3단계 : 다른 탭 페이지에서 정보(제목,상세,링크) 추출......')\n",
        "    t_list, d_list, link_list = [], [], []\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    #main_pack > section > div.api_subject_bx > ul > li:nth-child(1) > div > div.detail_box > div.title_area > a\n",
        "    ul = soup.select_one('ul.lst_view._fe_view_infinite_scroll_append_target') #공백에 있을 경우 . 사용\n",
        "    # 제목, 링크 추출하기\n",
        "    contents = ul.select('li > div > div > div.title_area > a')\n",
        "    for content in contents:\n",
        "        t_list.append(content.get_text())       # 제목\n",
        "    # 상세설명 추출하기\n",
        "    contents = ul.select('li > div > div > div.dsc_area > a') # 상세설명\n",
        "    for content in contents:\n",
        "        link_list.append(content.attrs['href']) # href 링크\n",
        "        d_list.append(content.get_text())\n",
        "\n",
        "    # DataFrame으로 만들기\n",
        "    data = {'title': t_list, 'desc':d_list,'link':link_list}\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a/i' )\n",
        "html = driver.page_source  # 페이지 소스 가져오기\n",
        "\n",
        "# 3.[CODE 3] : 다른 탭 페이지에서 정보(ex: 제목,상세,링크) 추출\n",
        "df = naver_html_parse(html)\n",
        "print('\\n완료 : 추출된 정보 표로 만들기......')\n",
        "print(f'Total[{len(df)} 건]')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84b91436",
      "metadata": {
        "id": "84b91436"
      },
      "source": [
        "#### [4단계] 페이지 자동 스크롤링한 후 정보 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658def73",
      "metadata": {
        "id": "658def73"
      },
      "outputs": [],
      "source": [
        "# 웹 드라이버매니저 설치\n",
        "!pip install webdriver-manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c9b2d8",
      "metadata": {
        "id": "58c9b2d8"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# 크롬 드라이버 자동 업데이트\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "#브라우저 꺼짐 방지\n",
        "chrome_options = Options()\n",
        "chrome_options.add_experimental_option(\"detach\", True)\n",
        "\n",
        "# 불필요한 에러 메시지 없애기\n",
        "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
        "\n",
        "# 드라이버 초기화\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "# [CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "def naver_main_search(driver, keyword):\n",
        "    print('\\n1단계 : 검색어 넣고 네이버 메인 검색......')\n",
        "    driver.get('https://www.naver.com/') # 웹페이지 로드\n",
        "    search_box = driver.find_element(By.XPATH, '//*[@id=\"query\"]')  # 검색 키워드 영역\n",
        "    search_button = driver.find_element(By.XPATH, '//*[@id=\"search-btn\"]') # 검색 버튼\n",
        "    print(f'search_box : {search_box}')\n",
        "    search_keyword = keyword  # 키워드\n",
        "    search_box.send_keys(search_keyword)\n",
        "    search_button.click()\n",
        "\n",
        "# [CODE 2] : 검색 결과에서 다른 탭 선택\n",
        "def naver_main_search_tab(driver, url, xpath):\n",
        "    print('\\n2단계 : 검색 결과에서 다른 탭 선택......')\n",
        "    print(f'      currnet_url={driver.current_url}')\n",
        "    driver.get(url) # 해당 웹페이지 로드\n",
        "    search_button = driver.find_element(By.XPATH, xpath) # target xpath\n",
        "    search_button.click()\n",
        "\n",
        "    # 페이지 자동 스크롤하기(3번)\n",
        "    print('2단계 : 페이지 자동 스크롤...')\n",
        "    actions = driver.find_element(By.CSS_SELECTOR, 'body')\n",
        "    time.sleep(2)\n",
        "    for _ in range(3):\n",
        "        actions.send_keys(Keys.END)\n",
        "        print('       page scroll...' )\n",
        "        time.sleep(2)\n",
        "\n",
        "# [CODE 3] : VIEW탭 페이지에서 정보(제목,상세,링크) 추출\n",
        "def naver_html_parse(html):\n",
        "    print('\\n3단계 : 다른 탭 페이지에서 정보(제목,상세,링크) 추출......')\n",
        "    t_list, d_list, link_list = [], [], []\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    #main_pack > section > div.api_subject_bx > ul > li:nth-child(1) > div > div.detail_box > div.title_area > a\n",
        "    ul = soup.select_one('ul.lst_view._fe_view_infinite_scroll_append_target') #공백에 있을 경우 . 사용\n",
        "    # 제목, 링크 추출하기\n",
        "    contents = ul.select('li > div > div > div.title_area > a')\n",
        "    for content in contents:\n",
        "        t_list.append(content.get_text())       # 제목\n",
        "    # 상세설명 추출하기\n",
        "    contents = ul.select('li > div > div > div.dsc_area > a') # 상세설명\n",
        "    for content in contents:\n",
        "        link_list.append(content.attrs['href']) # href 링크\n",
        "        d_list.append(content.get_text())\n",
        "\n",
        "    # DataFrame으로 만들기\n",
        "    data = {'title': t_list, 'desc':d_list,'link':link_list}\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "keyword = input('페이지 검색어 입력: ')\n",
        "\n",
        "# 1.[CODE 1] : 검색어 넣고 네이버 메인 검색\n",
        "naver_main_search(driver, keyword)\n",
        "\n",
        "# 2.[CODE 2] : 검색 결과에서 VIEW 탭 선택\n",
        "naver_main_search_tab(driver, driver.current_url, '//*[@id=\"lnb\"]/div[1]/div/div[1]/div/div[1]/div[1]/a/i' )\n",
        "html = driver.page_source  # 페이지 소스 가져오기\n",
        "\n",
        "# 3.[CODE 3] : 다른 탭 페이지에서 정보(제목,상세,링크) 추출\n",
        "df = naver_html_parse(html)\n",
        "print('\\n완료 : 추출된 정보 표로 만들기......')\n",
        "print(f'Total[{len(df)} 건]')\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4d5d79",
      "metadata": {
        "id": "5a4d5d79",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93264ee",
      "metadata": {
        "id": "c93264ee"
      },
      "source": [
        "-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882b6a04",
      "metadata": {
        "id": "882b6a04"
      },
      "source": [
        "#### [실습]  커피빈매장 정보 크롤링하여 파일로 저장하기\n",
        "- 아래 사이트를 이용해 호출해야할 자바스크립트 함수를 확인하다.\n",
        "- https://www.coffeebeankorea.com\n",
        "- https://www.coffeebeankorea.com/store/store.asp\n",
        "- (매장 번호로) 자세히보기: javascript:storePop2('374');\n",
        "- chromedriver.exe 파일 위치는 코드와 동일한 위치에 놓는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889f4ed3",
      "metadata": {
        "id": "889f4ed3"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "MAX = 10     # 추출 데이터 건수\n",
        "FILE = './CoffeeBean_매장정보.csv'\n",
        "\n",
        "#[CODE 1]\n",
        "def getStoreInfo():\n",
        "    CoffeeBean_URL = \"https://www.coffeebeankorea.com/store/store.asp\"\n",
        "\n",
        "    # 드라이버 초기화\n",
        "    driver = webdriver.Chrome()\n",
        "\n",
        "    result = []  # 데이터 저장 변수\n",
        "    total, cnt = 370, 0\n",
        "    for i in range(1, total+1):  #매장 수 만큼(370) 반복\n",
        "        driver.get(CoffeeBean_URL)\n",
        "        time.sleep(1)  #웹페이지 연결할 동안 1초 대기\n",
        "        try:\n",
        "            print(f'read[{i}]')\n",
        "            driver.execute_script(\"storePop2(%d)\" %i)\n",
        "            time.sleep(1) #스크립트 실행 할 동안 1초 대기\n",
        "\n",
        "            html = driver.page_source\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            store_name_h2 = soup.select(\"div.store_txt > h2\")\n",
        "            store_name = store_name_h2[0].string  #매장 이름\n",
        "\n",
        "            store_info = soup.select(\"div.store_txt > table.store_table > tbody > tr > td\")\n",
        "            store_address_list = list(store_info[2])\n",
        "            store_address = store_address_list[0]  #매장 주소\n",
        "\n",
        "            store_phone = store_info[3].string     #매장 전화번호\n",
        "            result.append([store_name]+[store_address]+[store_phone])\n",
        "            cnt += 1\n",
        "            # 매장정보 가져온 데이터 출력하기\n",
        "            print(\"save[%3d] %3d - %s\" % (cnt, i, store_name))\n",
        "\n",
        "             # MAX값에 해당하는 건수 만큼만 실행하기\n",
        "            if cnt >= MAX:\n",
        "                break\n",
        "\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return result\n",
        "\n",
        "#---------------\n",
        "# main\n",
        "#---------------\n",
        "#[CODE 0]\n",
        "def main():\n",
        "    result = []\n",
        "    print('CoffeeBean store crawling >>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
        "    result = getStoreInfo()  #[매장 추출 함수]호출하기   #[CODE 1] 호출\n",
        "    coffeebean_tbl = pd.DataFrame(result, columns=('store', 'address','phone'))\n",
        "    coffeebean_tbl.to_csv(FILE, encoding='cp949', mode='w', index=True)  # 파일로 저장하기\n",
        "    del result[:]\n",
        "    return coffeebean_tbl\n",
        "\n",
        "\n",
        "df = main() #[CODE 0] 호출\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641f3d97",
      "metadata": {
        "id": "641f3d97"
      },
      "source": [
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d30286",
      "metadata": {
        "id": "75d30286"
      },
      "source": [
        "### **[미션] : Selenium을 이용하여 동적인 정보 추출하여 표로 만들기**\n",
        "- 1. 자신이 원하는 웹 페이지를 정해서 동적인 정보를 100개 이상 추출하기\n",
        "- 2. Pandas DataFrame 표로 나타내기\n",
        "- 3. CSV file로 저장하기\n",
        "  4. Slack에 코드 업로드하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d9596d",
      "metadata": {
        "id": "10d9596d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}